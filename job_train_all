#!/usr/bin/env bash

#SBATCH --partition=gpu-long  # Partition to submit to
#SBATCH --job-name=fine_train
#SBATCH --ntasks-per-node=1
#SBATCH --array=0-12
#SBATCH --constraint="[a40|a100]"
#SBATCH --gres=gpu:1
# Runtime in D-HH:MM
#SBATCH --time=1-20:00:00
#SBATCH --mem=50G    
#SBATCH --output=./training_output_debug/slurm-%A_%a.out # STDOUT

echo "SLURM_JOBID: " $SLURM_JOBID
echo "SLURM_ARRAY_TASK_ID: " $SLURM_ARRAY_TASK_ID
echo "SLURM_ARRAY_JOB_ID: " $SLURM_ARRAY_JOB_ID

base_dir=/scratch/workspace/pradyumngoya_umass_edu-merge/
data_root=partnet_mobility_root
split_index=0
python -u train.py --base_dir=$base_dir --data_root=$data_root --split_index=$split_index --category_index=$SLURM_ARRAY_TASK_ID
python -u train.py --base_dir=$base_dir --data_root=$data_root --split_index=$split_index --encode_part --category_index=$SLURM_ARRAY_TASK_ID
python -u train.py --base_dir=$base_dir --data_root=$data_root --split_index=$split_index --encode_shape --category_index=$SLURM_ARRAY_TASK_ID
python -u train.py --base_dir=$base_dir --data_root=$data_root --split_index=$split_index --encode_part --encode_shape --category_index=$SLURM_ARRAY_TASK_ID